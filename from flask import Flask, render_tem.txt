from flask import Flask, render_template, request, redirect, url_for, flash, jsonify, session
from flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user
from flask_mysqldb import MySQL
from werkzeug.security import generate_password_hash, check_password_hash
from flask_cors import CORS
import cv2
import numpy as np
from tensorflow.keras.models import load_model
import librosa
import os
import base64
import tempfile
import logging
import traceback
from flask_dance.contrib.google import make_google_blueprint, google
from pydub import AudioSegment
from pydub.utils import which
import random

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize Flask app
app = Flask(__name__)
app.config['SECRET_KEY'] = 'alina123456789secretkey'

# Database Configuration
app.config['MYSQL_HOST'] = 'localhost'
app.config['MYSQL_USER'] = 'moodtunes'
app.config['MYSQL_PASSWORD'] = 'alina'
app.config['MYSQL_DB'] = 'moodtunes'

mysql = MySQL(app)
CORS(app)

# Initialize Login Manager
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = 'login'

# Google OAuth Configuration
GOOGLE_CLIENT_ID = "293853184931-fptjkke22fesaceuen17kbc2d56fiueb.apps.googleusercontent.com"
GOOGLE_CLIENT_SECRET = "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"

google_bp = make_google_blueprint(
    client_id=GOOGLE_CLIENT_ID,
    client_secret=GOOGLE_CLIENT_SECRET,
    scope=["profile", "email"],
    redirect_to="google_callback"
)

app.register_blueprint(google_bp, url_prefix="/login")


# üéµ Store all YouTube Music Playlists here (Place this after `app = Flask(__name__)`)
playlists = {
    "neutral": [
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37uk_tjHNIsoRHSbNaP0mwu-&si=WELMDxrLGjF0-F1g",
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37vM0Zg2L6_JZ94LhXzl5Bd3&si=vEzZc-E5X2FLTpJO",
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37uNGP60aBFQohdjBWTbJhAW&si=PO_a6bCyysE04GwG"
    ],
    "happy": [
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37uMhId3l6FVXuntPja1N_KQ&si=iVjml2KfmYvgqqwq",
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37sqOmvkrKqKJRyPNAzoyQLA&si=gSzhIXETK2W-E6OD",
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37txkKa7jSH-8eMdOrGpOZMa&si=L5CgIxFvriv5gDgc"
    ],
    "sad": [
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37tmIr1QSaGDnByR2_yWHvtk&si=sdRRwJL-fzzRliZP",
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37vsycG1M3vAa8yqAa1Ay_Qv&si=kAYLMJAPWP_YI87L",
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37vQ_pknSe2gV_QTFjKXajQt&si=wvHkyvfBgpjSer91"
    ],
    "angry": [
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37vDTyudI5pM1f5JFxJAGgyA&si=i56vtAOAKDbRpaOg",
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37sftv_tr6hBBtDTiV4Dd1M3&si=nKkrIvBc1Edd67sJ",
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37uCZajoDTg5Q22TgNN9vq0F&si=4CjaUmQHsGCjgtOS"
    ],
    "fearful": [
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37ukU5rbvmSjI009eQMJ3ybZ&si=bAZUgqzpj3Nj7-ei",
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37tH0nuko2Mq2t3-RrX7wtLJ&si=fXO7ug15IgTLodXD",
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37uPMlFzqGkp0VHW-vK0NycK&si=bjLoyaSmIMCUh144"
    ],
    "surprised": [
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37tb8Da4kMiWIqEnOv4L9fFe&si=H30KtlX0OyiuG7Tt",
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37swfNhL4zwF_LxqQ-ewV942&si=Sgx2Q6Usiiub6NF0",
        "https://music.youtube.com/playlist?list=PLpZgDvLZI37vgMHyy5uI5BZys_JBcR8WS&si=VoJVWJKExia6BZ7F"
    ]
}

# Model Paths
MODEL_DIR = r'C:\Users\alina_2pzmzug\moodtunes\models'
FACE_MODEL_PATH = os.path.join(MODEL_DIR, 'facemodel.h5')
VOICE_MODEL_PATH = os.path.join(MODEL_DIR, 'voicemodel.h5')

# Global variables for models
facial_model = None
voice_model = None
face_cascade = None

# Create a safer folder to store audio files
SAFE_AUDIO_FOLDER = r"C:\Users\alina_2pzmzug\Desktop\temp_audio"
os.makedirs(SAFE_AUDIO_FOLDER, exist_ok=True)

# Path to emotion-based songs folder
SONGS_DIR = r"C:\Users\alina_2pzmzug\moodtunes\songs"

def load_models():
    """Load all required models with error handling."""
    global facial_model, voice_model, face_cascade
    
    try:
        if os.path.exists(FACE_MODEL_PATH):
            facial_model = load_model(FACE_MODEL_PATH)
            logger.info("‚úÖ Facial model loaded successfully")
        else:
            logger.error(f"‚ùå Facial model not found at {FACE_MODEL_PATH}")

        if os.path.exists(VOICE_MODEL_PATH):
            voice_model = load_model(VOICE_MODEL_PATH)
            logger.info("‚úÖ Voice model loaded successfully")
            logger.info(f"Voice model input shape: {voice_model.input_shape}")
        else:
            logger.error(f"‚ùå Voice model not found at {VOICE_MODEL_PATH}")

        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        logger.info("‚úÖ Face cascade classifier loaded successfully")
        
    except Exception as e:
        logger.error(f"‚ùå Error loading models: {str(e)}")
        logger.error(traceback.format_exc())

# Load models on startup
load_models()

# Emotion Labels
facial_emotions = {0: "Angry", 1: "Fearful", 2: "Happy", 3: "Neutral", 4: "Sad", 5: "Surprised"}
voice_emotions = ["angry", "fearful", "happy", "neutral", "sad", "surprised"]

# Process Facial Image
def process_facial_image(image_data):
    """Process base64 encoded facial image for emotion detection."""
    try:
        # Extract base64 data if needed
        if 'base64,' in image_data:
            image_data = image_data.split('base64,')[1]
        
        # Decode image
        image_bytes = base64.b64decode(image_data)
        nparr = np.frombuffer(image_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

        if img is None:
            raise ValueError("Failed to decode image")

        # Convert to grayscale and detect faces
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

        if len(faces) == 0:
            raise ValueError("No face detected in image")

        # Process the first detected face
        x, y, w, h = faces[0]
        roi_gray = gray[y:y+h, x:x+w]
        roi_gray = cv2.resize(roi_gray, (48, 48))
        roi_gray = roi_gray / 255.0
        roi_gray = np.expand_dims(np.expand_dims(roi_gray, -1), 0)

        logger.info("‚úÖ Face processed successfully")
        return roi_gray

    except Exception as e:
        logger.error(f"‚ùå Error processing facial image: {str(e)}")
        logger.error(traceback.format_exc())
        raise

def convert_webm_to_wav(webm_path, wav_path):
    """Convert a .webm audio file to .wav format."""
    audio = AudioSegment.from_file(webm_path, format="webm")
    audio.export(wav_path, format="wav")
    return wav_path

def process_voice_data(audio_file):
    """Process voice recording for emotion detection."""
    temp_webm = None
    temp_wav = None
    try:
        logger.info("üéµ Starting voice processing...")

        # Save WebM file in a safe location
        webm_path = os.path.join(SAFE_AUDIO_FOLDER, "recorded_audio.webm")
        audio_file.save(webm_path)
        logger.info(f"‚úÖ WebM audio saved: {webm_path}")

        # Confirm the file exists before processing
        if not os.path.exists(webm_path):
            raise FileNotFoundError(f"‚ùå WebM file not found: {webm_path}")

        # Convert WebM to WAV
        temp_wav = os.path.join(SAFE_AUDIO_FOLDER, "recorded_audio.wav")
        convert_webm_to_wav(webm_path, temp_wav)

        # Confirm the WAV file was created
        if not os.path.exists(temp_wav):
            raise FileNotFoundError(f"‚ùå WAV file not created: {temp_wav}")

        logger.info(f"‚úÖ Successfully converted to WAV: {temp_wav}")

        # Load audio with specific parameters
        y, sr = librosa.load(temp_wav, duration=5, sr=22050)
        logger.info(f"‚úÖ Audio loaded: duration={len(y)/sr:.2f}s, sr={sr}Hz")

        # Ensure audio is exactly 5 seconds
        target_length = 5 * sr
        if len(y) < target_length:
            logger.info(f"Padding audio from {len(y)} to {target_length} samples")
            y = np.pad(y, (0, target_length - len(y)))
        else:
            logger.info(f"Truncating audio to {target_length} samples")
            y = y[:target_length]

        # Extract MFCC features
        mfcc = librosa.feature.mfcc(
            y=y,
            sr=sr,
            n_mfcc=13,
            n_fft=2048,  # Ensure this matches training parameters
            hop_length=512  # Ensure this matches training parameters
        )
        logger.info(f"‚úÖ Initial MFCC shape: {mfcc.shape}")
        logger.info(f"MFCC Shape: {mfcc.shape}, Mean: {np.mean(mfcc)}, Std Dev: {np.std(mfcc)}")

        # Ensure exactly 94 frames
        if mfcc.shape[1] > 94:
            logger.info("Truncating frames to 94")
            mfcc = mfcc[:, :94]
        elif mfcc.shape[1] < 94:
            logger.info(f"Padding frames from {mfcc.shape[1]} to 94")
            pad_width = 94 - mfcc.shape[1]
            mfcc = np.pad(mfcc, ((0, 0), (0, pad_width)), mode='constant')

        # Normalize features using training dataset statistics
        TRAINING_MEAN = -5  # Replace with the actual mean from training
        TRAINING_STD = 10    # Replace with actual std dev from training
        mfcc = (mfcc - TRAINING_MEAN) / (TRAINING_STD + 1e-8)

        # Reshape for model input
        features = np.expand_dims(mfcc, axis=0)
        logger.info(f"‚úÖ Final features shape: {features.shape}")

        return features

    except Exception as e:
        logger.error(f"‚ùå Error processing voice data: {str(e)}")
        logger.error(traceback.format_exc())
        raise

    finally:
        # Clean up temporary files
        if temp_webm:
            try:
                os.unlink(temp_webm.name)
                logger.info("‚úÖ Temporary WebM file cleaned up")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Failed to delete temporary WebM file: {str(e)}")
        
        if temp_wav:
            try:
                os.unlink(temp_wav)
                logger.info("‚úÖ Temporary WAV file cleaned up")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Failed to delete temporary WAV file: {str(e)}")

# User Class
class User(UserMixin):
    def __init__(self, id, name, email):
        self.id = id
        self.name = name
        self.email = email

@login_manager.user_loader
def load_user(user_id):
    """Load user by ID for Flask-Login."""
    try:
        cursor = mysql.connection.cursor()
        cursor.execute('SELECT * FROM users WHERE id = %s', (user_id,))
        user = cursor.fetchone()
        cursor.close()
        
        if user:
            return User(user[0], user[1], user[2])
    except Exception as e:
        logger.error(f"‚ùå Error loading user: {str(e)}")
    return None

def verify_user(email, password):
    """Verify user credentials."""
    try:
        cursor = mysql.connection.cursor()
        cursor.execute('SELECT * FROM users WHERE email = %s', (email,))
        user = cursor.fetchone()
        cursor.close()

        if user and check_password_hash(user[3], password):
            return User(user[0], user[1], user[2])
    except Exception as e:
        logger.error(f"‚ùå Error verifying user: {str(e)}")
    return None

def save_emotion_to_db(user_id, emotion_type, emotion, confidence):
    """Save detected emotion to database."""
    try:
        cursor = mysql.connection.cursor()
        cursor.execute(
            'INSERT INTO emotion_history (user_id, emotion_type, emotion, confidence, timestamp) VALUES (%s, %s, %s, %s, NOW())',
            (user_id, emotion_type, emotion, confidence)
        )
        mysql.connection.commit()
        cursor.close()
        logger.info("‚úÖ Emotion saved to database")
        return True
    except Exception as e:
        logger.error(f"‚ùå Error saving emotion to database: {str(e)}")
        return False

def get_user_emotion_history(user_id):
    """Get user's emotion detection history."""
    try:
        cursor = mysql.connection.cursor()
        cursor.execute(
            'SELECT emotion_type, emotion, confidence, timestamp FROM emotion_history WHERE user_id = %s ORDER BY timestamp DESC LIMIT 10',
            (user_id,)
        )
        history = cursor.fetchall()
        cursor.close()
        return history
    except Exception as e:
        logger.error(f"‚ùå Error fetching emotion history: {str(e)}")
        return []

# Routes
@app.route('/')
def index():
    return redirect(url_for('login'))

@app.route('/login', methods=['GET', 'POST'])
def login():
    if current_user.is_authenticated:
        return redirect(url_for('dashboard'))

    if request.method == 'POST':
        email = request.form.get('email')
        password = request.form.get('password')

        if not all([email, password]):
            flash('All fields are required!', 'error')
            return redirect(url_for('login'))

        user = verify_user(email, password)

        if user:
            login_user(user)
            flash('Login successful!', 'success')
            return redirect(url_for('dashboard'))
        else:
            flash('Invalid email or password', 'error')
            return redirect(url_for('login'))

    return render_template('login.html')

@app.route('/register', methods=['GET', 'POST'])
def register():
    if current_user.is_authenticated:
        return redirect(url_for('dashboard'))

    if request.method == 'POST':
        name = request.form.get('name')
        email = request.form.get('email')
        password = request.form.get('password')
        confirm_password = request.form.get('confirm-password')

        if not all([name, email, password, confirm_password]):
            flash('All fields are required!', 'error')
            return redirect(url_for('register'))

        if password != confirm_password:
            flash('Passwords do not match!', 'error')
            return redirect(url_for('register'))

        try:
            cursor = mysql.connection.cursor()
            cursor.execute('SELECT * FROM users WHERE email = %s', (email,))
            
            if cursor.fetchone():
                flash('Email already registered!', 'error')
                return redirect(url_for('register'))

            hashed_password = generate_password_hash(password)
            cursor.execute('INSERT INTO users (name, email, password) VALUES (%s, %s, %s)',
                           (name, email, hashed_password))
            mysql.connection.commit()
            cursor.close()
            
            flash('Registration successful! Please log in.', 'success')
            return redirect(url_for('login'))

        except Exception as e:
            flash('Registration failed! Please try again.', 'error')
            logger.error(f"Registration error: {e}")
            return redirect(url_for('register'))

    return render_template('register.html')

@app.route('/dashboard')
@login_required
def dashboard():
    return render_template('dashboard.html', user=current_user)

@app.route('/logout')
@login_required
def logout():
    logout_user()
    return redirect(url_for('login'))

# Emotion Detection Routes
@app.route('/detect-facial-emotion', methods=['POST'])
@login_required
def detect_facial_emotion():
    """Detect emotion from facial image."""
    try:
        if not request.is_json:
            return jsonify({'status': 'error', 'message': 'Invalid content type'}), 400

        image_data = request.json.get('image')
        if not image_data:
            return jsonify({'status': 'error', 'message': 'No image data received'}), 400

        logger.info("üì∏ Received facial emotion detection request")

        face_roi = process_facial_image(image_data)
        if face_roi is None:
            return jsonify({'status': 'error', 'message': 'Failed to process image - no face detected'}), 400

        # Make prediction
        prediction = facial_model.predict(face_roi)
        maxindex = int(np.argmax(prediction))
        emotion = facial_emotions[maxindex]
        confidence = float(prediction[0][maxindex])

        logger.info(f"üòä Detected facial emotion: {emotion} with confidence: {confidence:.2f}")

        # Save to database
        if save_emotion_to_db(current_user.id, 'facial', emotion, confidence):
            logger.info("‚úÖ Emotion saved to database")
        else:
            logger.warning("‚ö†Ô∏è Failed to save emotion to database")

        return jsonify({
            'status': 'success',
            'emotion': emotion,
            'confidence': confidence
        })

    except Exception as e:
        logger.error(f"‚ùå Error in facial emotion detection: {str(e)}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/detect-voice-emotion', methods=['POST'])
@login_required
def detect_voice_emotion():
    """Detect voice emotion and debug issues."""
    try:
        if 'audio' not in request.files:
            logger.error("‚ùå No audio file received")
            return jsonify({'status': 'error', 'message': 'No audio file received'}), 400

        audio_file = request.files['audio']
        if audio_file.filename == '':
            logger.error("‚ùå Empty filename received")
            return jsonify({'status': 'error', 'message': 'No selected file'}), 400

        logger.info("üé§ Processing voice emotion detection request")

        # Process audio
        processed_data = process_voice_data(audio_file)
        if processed_data is None:
            logger.error("‚ùå Failed to process audio")
            return jsonify({'status': 'error', 'message': 'Failed to process audio'}), 400

        logger.info(f"‚úÖ Processed audio shape: {processed_data.shape}")

        # **Check if input shape is correct before predicting**
        if processed_data.shape != (1, 13, 94):
            logger.error(f"‚ùå Wrong input shape! Expected (1, 13, 94), got {processed_data.shape}")
            return jsonify({'status': 'error', 'message': 'Incorrect input shape'}), 400

        # Make prediction
        prediction = voice_model.predict(processed_data, verbose=0)
        logger.info(f"üéµ Raw model predictions: {prediction}")

        # Get detected emotion
        maxindex = int(np.argmax(prediction))
        emotion = voice_emotions[maxindex]
        confidence = float(prediction[0][maxindex])

        logger.info(f"üéµ Detected voice emotion: {emotion} with confidence: {confidence:.2f}")

        # **Check if confidence is too low**
        if confidence < 0.50:
            logger.warning(f"‚ö†Ô∏è Low confidence ({confidence:.2f}) - Prediction may be unreliable")

        # Debug label mapping
        logger.info(f"üìå Label mapping: {voice_emotions}")
        logger.info(f"üìå Model predicted index {maxindex}, which corresponds to '{emotion}'")

        # Save to database
        if save_emotion_to_db(current_user.id, 'voice', emotion, confidence):
            logger.info("‚úÖ Emotion saved to database")
        else:
            logger.warning("‚ö†Ô∏è Failed to save emotion to database")

        return jsonify({
            'status': 'success',
            'emotion': emotion,
            'confidence': confidence
        })

    except Exception as e:
        logger.error(f"‚ùå Error in voice emotion detection: {str(e)}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/emotion-history')
@login_required
def emotion_history():
    """Get user's emotion detection history."""
    try:
        history = get_user_emotion_history(current_user.id)
        return jsonify({
            'status': 'success',
            'history': [{
                'type': h[0],
                'emotion': h[1],
                'confidence': float(h[2]),
                'timestamp': h[3].isoformat()
            } for h in history]
        })
    except Exception as e:
        logger.error(f"‚ùå Error fetching emotion history: {str(e)}")
        return jsonify({'status': 'error', 'message': str(e)}), 500


# ‚úÖ ADD THIS FUNCTION AT THE BOTTOM BEFORE `if __name__ == '__main__'`
@app.route('/recommend/<emotion>', methods=['GET'])
def recommend_music(emotion):
    """Returns a random YouTube Music playlist based on detected emotion."""
    if emotion in playlists:
        return jsonify({"playlist": random.choice(playlists[emotion])})
    return jsonify({"error": "Emotion not found"}), 400

# Error Handlers
@app.errorhandler(404)
def not_found_error(error):
    return render_template('404.html'), 404

@app.errorhandler(500)
def internal_error(error):
    mysql.connection.rollback()
    return render_template('500.html'), 500

# Main Application Entry
if __name__ == '__main__':
    try:
        app.run(
            host='0.0.0.0',
            port=5000,
            debug=True
        )
    except Exception as e:
        logger.error(f"‚ùå Error starting server: {str(e)}")